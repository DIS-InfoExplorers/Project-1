{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a33f2d-bf7b-43b5-b56a-0b61eebbf0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import string\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from collections import Counter\n",
    "from math import log\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from scipy.sparse.linalg import norm as sparse_norm\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b294de-1cb4-4399-a7eb-e27912e381b1",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "299d5d6d-9c33-48fd-9817-b7e8e2141411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000000</th>\n",
       "      <td>0</td>\n",
       "      <td>The presence of communication amid scientific ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966376</th>\n",
       "      <td>8</td>\n",
       "      <td>In June 1942, the United States Army Corps of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468831</th>\n",
       "      <td>12</td>\n",
       "      <td>Tutorial: Introduction to Restorative Justice....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000001</th>\n",
       "      <td>16</td>\n",
       "      <td>The approach is based on a theory of justice t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306952</th>\n",
       "      <td>23</td>\n",
       "      <td>Phloem is a conductive (or vascular) tissue fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950989</th>\n",
       "      <td>8841780</td>\n",
       "      <td>Wolves don't hide. They don't even live in cav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395590</th>\n",
       "      <td>8841787</td>\n",
       "      <td>The UNHCR Country Representative in Kenya. Str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93101</th>\n",
       "      <td>8841790</td>\n",
       "      <td>2. Describe the misery at Kakuma. 3. Compariso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669122</th>\n",
       "      <td>8841800</td>\n",
       "      <td>Following the death of his employer and mentor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593471</th>\n",
       "      <td>8841801</td>\n",
       "      <td>Presently, Puerto Rico holds the most titles f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1471406 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         corpus-id                                               text\n",
       "1000000          0  The presence of communication amid scientific ...\n",
       "966376           8  In June 1942, the United States Army Corps of ...\n",
       "468831          12  Tutorial: Introduction to Restorative Justice....\n",
       "1000001         16  The approach is based on a theory of justice t...\n",
       "306952          23  Phloem is a conductive (or vascular) tissue fo...\n",
       "...            ...                                                ...\n",
       "950989     8841780  Wolves don't hide. They don't even live in cav...\n",
       "395590     8841787  The UNHCR Country Representative in Kenya. Str...\n",
       "93101      8841790  2. Describe the misery at Kakuma. 3. Compariso...\n",
       "669122     8841800  Following the death of his employer and mentor...\n",
       "593471     8841801  Presently, Puerto Rico holds the most titles f...\n",
       "\n",
       "[1471406 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_json('data/corpus.jsonl', lines=True).sort_values(by=[\"_id\"]).rename(columns={\"_id\": \"corpus-id\"})\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851459ae-b7f1-42d0-80cb-5e59e88652f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>506217</th>\n",
       "      <td>2</td>\n",
       "      <td>Androgen receptor define</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65864</th>\n",
       "      <td>3</td>\n",
       "      <td>Another name for the primary visual cortex is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372466</th>\n",
       "      <td>4</td>\n",
       "      <td>Defining alcoholism as a disease is associated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326447</th>\n",
       "      <td>5</td>\n",
       "      <td>ECT is a treatment that is used for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117580</th>\n",
       "      <td>6</td>\n",
       "      <td>Ebolavirus is an enveloped virus, which means</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158901</th>\n",
       "      <td>1185863</td>\n",
       "      <td>why did rachel carson die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83120</th>\n",
       "      <td>1185864</td>\n",
       "      <td>definition of ramen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7634</th>\n",
       "      <td>1185865</td>\n",
       "      <td>amex india customer care number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1185868</td>\n",
       "      <td>_________ justice is designed to repair the ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1185869</td>\n",
       "      <td>)what was the immediate impact of the success ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        query-id                                               text\n",
       "506217         2                           Androgen receptor define\n",
       "65864          3      Another name for the primary visual cortex is\n",
       "372466         4  Defining alcoholism as a disease is associated...\n",
       "326447         5                ECT is a treatment that is used for\n",
       "117580         6      Ebolavirus is an enveloped virus, which means\n",
       "...          ...                                                ...\n",
       "158901   1185863                          why did rachel carson die\n",
       "83120    1185864                                definition of ramen\n",
       "7634     1185865                    amex india customer care number\n",
       "1        1185868  _________ justice is designed to repair the ha...\n",
       "0        1185869  )what was the immediate impact of the success ...\n",
       "\n",
       "[509962 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = pd.read_json(path_or_buf='data/queries.jsonl', lines=True).sort_values(by=[\"_id\"])\n",
    "queries['text'] = queries['text'].str.strip()#.apply(tokenize)\n",
    "queries = queries.drop(columns=[\"metadata\"]).rename(columns={\"_id\": \"query-id\"})\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4b0aef4-1037-4514-86d1-3c6014fbf028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70257</th>\n",
       "      <td>3</td>\n",
       "      <td>1142680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395137</th>\n",
       "      <td>4</td>\n",
       "      <td>5613529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346352</th>\n",
       "      <td>5</td>\n",
       "      <td>4956428</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125307</th>\n",
       "      <td>6</td>\n",
       "      <td>1931409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66896</th>\n",
       "      <td>8</td>\n",
       "      <td>1094214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169115</th>\n",
       "      <td>1185863</td>\n",
       "      <td>2545716</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88577</th>\n",
       "      <td>1185864</td>\n",
       "      <td>1408016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>1185865</td>\n",
       "      <td>229186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1185868</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1185869</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532751 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        query-id  corpus-id  score\n",
       "70257          3    1142680      1\n",
       "395137         4    5613529      1\n",
       "346352         5    4956428      1\n",
       "125307         6    1931409      1\n",
       "66896          8    1094214      1\n",
       "...          ...        ...    ...\n",
       "169115   1185863    2545716      1\n",
       "88577    1185864    1408016      1\n",
       "8141     1185865     229186      1\n",
       "1        1185868         16      1\n",
       "0        1185869          0      1\n",
       "\n",
       "[532751 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_corpus_train_map = pd.read_csv(\"data/task1_train.tsv\", sep=\"\\t\")\n",
    "query_corpus_train_map.sort_values(by=\"query-id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a46d67-bc34-4757-b450-80d9ee85fa70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Another name for the primary visual cortex is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Defining alcoholism as a disease is associated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>ECT is a treatment that is used for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Ebolavirus is an enveloped virus, which means</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>In humans, the normal set point for body tempe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>18204</td>\n",
       "      <td>anger is fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7433</th>\n",
       "      <td>18205</td>\n",
       "      <td>anger management definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7434</th>\n",
       "      <td>18208</td>\n",
       "      <td>angie baby meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7435</th>\n",
       "      <td>18209</td>\n",
       "      <td>angie lindvall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7436</th>\n",
       "      <td>18211</td>\n",
       "      <td>angies list customer service phone number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7437 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      query-id                                               text\n",
       "0            3      Another name for the primary visual cortex is\n",
       "1            4  Defining alcoholism as a disease is associated...\n",
       "2            5                ECT is a treatment that is used for\n",
       "3            6      Ebolavirus is an enveloped virus, which means\n",
       "4            8  In humans, the normal set point for body tempe...\n",
       "...        ...                                                ...\n",
       "7432     18204                                      anger is fear\n",
       "7433     18205                        anger management definition\n",
       "7434     18208                                 angie baby meaning\n",
       "7435     18209                                     angie lindvall\n",
       "7436     18211          angies list customer service phone number\n",
       "\n",
       "[7437 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_train = pd.merge(queries, query_corpus_train_map, left_on='query-id', right_on='query-id', how='inner').drop(columns=[ \"score\",\"corpus-id\"])\n",
    "queries_train_subset = queries_train.iloc[:7437, :]\n",
    "queries_train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd8df4c3-4107-46ff-ac76-62e87c2a6cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Androgen receptor define</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1215</td>\n",
       "      <td>3 levels of government in canada and their res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1288</td>\n",
       "      <td>3/5 of 60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1576</td>\n",
       "      <td>60x40 slab cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2235</td>\n",
       "      <td>Bethel University was founded in what year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>1102335</td>\n",
       "      <td>why do people buy cars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7433</th>\n",
       "      <td>1102351</td>\n",
       "      <td>why do jefferson and stanton include these sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7434</th>\n",
       "      <td>1102390</td>\n",
       "      <td>why do children get aggressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7435</th>\n",
       "      <td>1102393</td>\n",
       "      <td>why do celebrate st patrick's day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7436</th>\n",
       "      <td>1102400</td>\n",
       "      <td>why do bears hibernate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7437 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      query-id                                               text\n",
       "0            2                           Androgen receptor define\n",
       "1         1215  3 levels of government in canada and their res...\n",
       "2         1288                                          3/5 of 60\n",
       "3         1576                                    60x40 slab cost\n",
       "4         2235         Bethel University was founded in what year\n",
       "...        ...                                                ...\n",
       "7432   1102335                             why do people buy cars\n",
       "7433   1102351  why do jefferson and stanton include these sim...\n",
       "7434   1102390                     why do children get aggressive\n",
       "7435   1102393                  why do celebrate st patrick's day\n",
       "7436   1102400                             why do bears hibernate\n",
       "\n",
       "[7437 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"data/task1_test.tsv\", sep=\"\\t\")\n",
    "queries_test = pd.merge(queries, df_test, left_on='query-id', right_on='query-id', how='inner').drop(columns=[\"id\"])\n",
    "queries_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493c6acb-d7aa-4aef-a7a0-a7e5a67aa136",
   "metadata": {},
   "source": [
    "# WATCH OUT HERE IS CRITIAL CHANGING CODE ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03bf908a-81e1-4627-af53-8febff3be90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used corpus length : 100001\n",
      "Used queries length : 100\n"
     ]
    }
   ],
   "source": [
    "queries2 = queries_train_subset.iloc[: 100]\n",
    "corpus2 = corpus.iloc[:100000]\n",
    "corpus2 = pd.concat([corpus2, corpus[corpus[\"corpus-id\"] == 1142680]])\n",
    "print(f\"Used corpus length : {len(corpus2)}\")\n",
    "print(f\"Used queries length : {len(queries2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8bd9e-f8cf-400e-b7f8-1b583fedc35b",
   "metadata": {},
   "source": [
    "# TF-IDF Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9378b82-4ada-4a18-9420-9bb500904c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary resources\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "STEMMER = PorterStemmer()\n",
    "LEMMATIZER = WordNetLemmatizer()\n",
    "\n",
    "# Precompile regex patterns for efficiency\n",
    "HTML_PATTERN = re.compile(\"(<.*?>)\")\n",
    "NON_ASCII_DIGITS_PATTERN = re.compile(\"(\\\\W|\\\\d)\")\n",
    "NON_ASCII_CHARS_PATTERN = re.compile(r'[^\\x00-\\x7F]+')\n",
    "\n",
    "# Convert stopwords list to set for faster lookup\n",
    "STOPWORDS_SET = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "030f9432-a022-4db1-a839-2329a27b06b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Optimized text preprocessing function.\"\"\"\n",
    "    \n",
    "    # Cleaning\n",
    "    text = HTML_PATTERN.sub(\"\", text)\n",
    "    text = NON_ASCII_DIGITS_PATTERN.sub(\" \", text)\n",
    "    text = NON_ASCII_CHARS_PATTERN.sub('', text)\n",
    "    text = \"\".join([ch for ch in text if ch not in string.punctuation])\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords, and then perform Stemming and Lemmatization\n",
    "    preprocessed_tokens = [\n",
    "        STEMMER.stem(LEMMATIZER.lemmatize(word))\n",
    "        for word in tokens\n",
    "        if word.lower() not in STOPWORDS_SET\n",
    "    ]\n",
    "    \n",
    "    return preprocessed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ed151b8-26cf-44c1-a2f7-ad6c24139a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_preprocess_texts(texts):\n",
    "    with Pool() as pool:\n",
    "        preprocessed_batches = pool.map(preprocess_text, texts)\n",
    "    return preprocessed_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a13d4985-6841-4cf6-89bf-21e3eeffcf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_tfidf_dataframe(documents, vocabulary):\n",
    "    # Create a list of dictionaries with term frequencies\n",
    "    list_of_dicts = [Counter(doc) for doc in documents]\n",
    "    \n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(list_of_dicts).fillna(0)\n",
    "    \n",
    "    # Reorder columns according to the vocabulary and fill missing columns with 0\n",
    "    df = df.reindex(columns=vocabulary, fill_value=0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def populate_tfidf_dataframe_sparse(documents, vocabulary):\n",
    "    # Create a sparse matrix to hold the term frequencies\n",
    "    tf_matrix = lil_matrix((len(documents), len(vocabulary)), dtype=int)\n",
    "\n",
    "    # Map each word in the vocabulary to its column index for faster lookup\n",
    "    vocab_index_map = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "\n",
    "    for i, doc in enumerate(documents):\n",
    "        for word in doc:\n",
    "            if word in vocab_index_map:\n",
    "                tf_matrix[i, vocab_index_map[word]] += 1\n",
    "\n",
    "    return tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd4a706a-ab9e-4b19-adb9-5337cb5abf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(corpus_text):\n",
    "    # Parallel tokenization and preprocessing\n",
    "    print(\"Process docs ...\")\n",
    "    documents = corpus_text.apply(lambda x: preprocess_text(x))\n",
    "\n",
    "    print(\"Create vocab ...\")\n",
    "    # Create the vocabulary\n",
    "    vocabulary = list(set(word for doc in documents for word in doc))\n",
    "    vocabulary.sort()\n",
    "    \n",
    "    # Use the helper function to create and populate the DataFrame for term frequencies\n",
    "    print(\"Compute tf ...\")\n",
    "    df = populate_tfidf_dataframe(documents, vocabulary)\n",
    "            \n",
    "    # Compute IDF values\n",
    "    print(\"Compute idf ...\")\n",
    "    doc_count = len(documents)\n",
    "    idf = df[df > 0].count().apply(lambda x: log(doc_count / x))\n",
    "    \n",
    "    # Compute TF-IDF values\n",
    "    print(\"Compute tf-idf ...\")\n",
    "    tfidf_df = df.apply(lambda x: x / x.sum(), axis=1).multiply(idf)\n",
    "    print(\"Done !\")\n",
    "    return documents, tfidf_df, vocabulary, idf\n",
    "\n",
    "def tfidf(corpus_text):\n",
    "    print(\"Process docs ... 2\")\n",
    "    documents = corpus_text.apply(lambda x: preprocess_text(x))\n",
    "\n",
    "    print(\"Create vocab ...\")\n",
    "    vocabulary = list(set(word for doc in documents for word in doc))\n",
    "    vocabulary.sort()\n",
    "\n",
    "    print(\"Compute tf ...\")\n",
    "    tf_matrix = populate_tfidf_dataframe_sparse(documents, vocabulary)\n",
    "\n",
    "    print(\"Compute idf ...\")\n",
    "    doc_count = len(documents)\n",
    "    df = (tf_matrix > 0).sum(axis=0)\n",
    "    idf = np.log(doc_count / df)\n",
    "\n",
    "    print(\"Compute tf-idf ...\")\n",
    "    tf_matrix = tf_matrix.tocsr()\n",
    "    tf_matrix = tf_matrix.multiply(1 / tf_matrix.sum(axis=1))\n",
    "    tfidf_matrix = tf_matrix.multiply(idf)\n",
    "\n",
    "    print(\"Done!\")\n",
    "    return documents, tfidf_matrix, vocabulary, idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41fed44e-b71d-4d7c-b70e-ff0b796739c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(query):\n",
    "    \"\"\"Tokenize, stem, and remove stopwords from the query.\"\"\"\n",
    "    return preprocess_text(query)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74293b0d-d5c6-4b1c-87a9-ab158e8c2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_query(query, vocabulary, idf):\n",
    "    \"\"\"Convert the query into its TF-IDF vector.\"\"\"\n",
    "    query_tf = Counter(preprocess_query(query))\n",
    "    query_vector = [query_tf.get(term, 0) * idf[term] for term in vocabulary]\n",
    "    return np.array(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14d73b3a-10a3-4d43-b99c-a0874bde346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_documents(tfidf_matrix_normalized, query_vectors, k):\n",
    "    \"\"\"Process multiple queries and return ranked document indices for each query.\"\"\"\n",
    "    \n",
    "    # Compute cosine similarities using matrix operations\n",
    "    similarity_matrix = linear_kernel(query_vectors, tfidf_matrix_normalized)\n",
    "    \n",
    "    # Get document indices ranked by relevance for each query\n",
    "    ranked_doc_indices = np.argsort(-similarity_matrix)[:, :k]\n",
    "    \n",
    "    return ranked_doc_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9b1d9a-fb90-41dc-87b9-bc4f37eea416",
   "metadata": {},
   "source": [
    "# Corpus Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "825e7fab-1ef8-40e6-b492-6ed1cc61a577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process docs ... 2\n",
      "Create vocab ...\n",
      "Compute tf ...\n",
      "Compute idf ...\n",
      "Compute tf-idf ...\n",
      "Done!\n",
      "CPU times: user 1min 47s, sys: 284 ms, total: 1min 47s\n",
      "Wall time: 1min 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ym/9zzn1f9j7c7dnh381g3rrm_m0000gn/T/ipykernel_29432/2510366936.py:44: RuntimeWarning: divide by zero encountered in divide\n",
      "  tf_matrix = tf_matrix.multiply(1 / tf_matrix.sum(axis=1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "_, tfidf, vocabulary, idf = tfidf(corpus2[\"text\"])\n",
    "len(corpus2[\"text\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61b242fb-0ce1-4499-ac6d-074fdaecee6f",
   "metadata": {},
   "source": [
    "l2_norms = sparse_norm(tfidf, axis=1)\n",
    "normalized_tfidf = tfidf / l2_norms[:, None]\n",
    "normalized_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db6d0c2-7a98-47fc-9b44-2cb782163ead",
   "metadata": {},
   "source": [
    "# Queries Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f0ab2d-c2b7-4555-aed1-82add60697a1",
   "metadata": {},
   "source": [
    "## Way 1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87eb87f6-8533-4801-8c74-2ada86deba3b",
   "metadata": {},
   "source": [
    "print(\"Vectorizing...\")\n",
    "queries2.loc[:, \"list\"] = queries2[\"text\"].apply(lambda x: vectorize_query(x, vocabulary, idf))\n",
    "print(\"Stacking...\")\n",
    "query_vectors = np.vstack(queries2[\"list\"])\n",
    "query_vectors.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "453e9ef5-ec2a-4cba-96db-45c96ab89956",
   "metadata": {},
   "source": [
    "prediction = predict_documents(tfidf_np, query_vectors, 10)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b091f30-ee70-44e1-a2bb-7c8b17764c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_to_ids_ranking(corpus, queries, prediction):\n",
    "    \n",
    "    mapped_results = [corpus.iloc[row]['corpus-id'].values for row in prediction]\n",
    "    df = pd.DataFrame(mapped_results)\n",
    "    df.insert(0, 'query-id', queries['query-id'].iloc[:len(df)])\n",
    "    df.columns = ['query-id'] + [f'rank-{i}' for i in range(1, df.shape[1])]\n",
    "    return df\n",
    "    \n",
    "#predictions_to_ids_ranking(corpus2, queries2, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd21a0-ee9f-49d2-818a-6fd17ee882d0",
   "metadata": {},
   "source": [
    "## Way 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09b0c291-7e22-468b-8451-9adc3b89e29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process queries 2 ...\n",
      "Initialize sparse matrix ...\n",
      "Compute  tf ...\n",
      "Multiply by idf ...\n",
      "Done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ym/9zzn1f9j7c7dnh381g3rrm_m0000gn/T/ipykernel_28579/2771484998.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  queries_df['processed'] = queries_df['text'].apply(preprocess_query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<100x22700 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 291 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize_queries(queries_df, vocabulary, idf):\n",
    "    \"\"\"Convert each query in the DataFrame into its TF-IDF vector.\"\"\"\n",
    "    \n",
    "    print(\"Process queries ...\")\n",
    "    # Preprocess all queries\n",
    "    queries_df.loc[:,'processed'] = queries_df['text'].apply(preprocess_query)\n",
    "\n",
    "    print(\"Prepare dataframe ...\")\n",
    "    # Flatten for efficient computation\n",
    "    flattened = queries_df.explode('processed')\n",
    "\n",
    "    print(\"Compute  tf ...\")\n",
    "    # Get dummy variables for each term\n",
    "    dummies = pd.get_dummies(flattened['processed']).groupby(flattened.index).sum()\n",
    "\n",
    "    print(\"Rename tf dataframe ...\")\n",
    "    # Create a DataFrame for term frequencies, using only the columns in our vocabulary\n",
    "    tf_df = dummies.reindex(columns=vocabulary, fill_value=0)\n",
    "\n",
    "    print(\"Multiply by idf ...\")\n",
    "    # Convert idf dictionary to a Series for easier multiplication\n",
    "    idf_series = pd.Series(idf)\n",
    "    \n",
    "    # Compute TF-IDF\n",
    "    tfidf_df = tf_df.multiply(idf_series, axis=1)\n",
    "    print(\"Done !\")\n",
    "    return tfidf_df\n",
    "\n",
    "def vectorize_queries(queries_df, vocabulary, idf):\n",
    "    \"\"\"Convert each query in the DataFrame into its TF-IDF vector.\"\"\"\n",
    "    \n",
    "    print(\"Process queries 2 ...\")\n",
    "    # Preprocess all queries\n",
    "    queries_df['processed'] = queries_df['text'].apply(preprocess_query)\n",
    "\n",
    "    print(\"Initialize sparse matrix ...\")\n",
    "    num_queries = len(queries_df)\n",
    "    num_terms = len(vocabulary)\n",
    "    \n",
    "    # Using a dictionary for term index lookup\n",
    "    vocab_dict = {term: index for index, term in enumerate(vocabulary)}\n",
    "    tf_matrix = lil_matrix((num_queries, num_terms))\n",
    "\n",
    "    print(\"Compute  tf ...\")\n",
    "    # Populate the sparse matrix\n",
    "    for idx, row in queries_df.iterrows():\n",
    "        for term in row['processed']:\n",
    "            if term in vocab_dict:\n",
    "                tf_matrix[idx, vocab_dict[term]] += 1\n",
    "\n",
    "    print(\"Multiply by idf ...\")\n",
    "    # Convert to CSR format for efficient multiplication and transform TFs to TF-IDF\n",
    "    tfidf_matrix = (tf_matrix.tocsr()).multiply(idf)\n",
    "\n",
    "    print(\"Done !\")\n",
    "    return tfidf_matrix\n",
    "\n",
    "vectors = vectorize_queries(queries2, vocabulary, idf)\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32fb1741-2b41-4984-8569-35285f8fb000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.28 s, sys: 920 ms, total: 4.2 s\n",
      "Wall time: 4.33 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>rank-1</th>\n",
       "      <th>rank-2</th>\n",
       "      <th>rank-3</th>\n",
       "      <th>rank-4</th>\n",
       "      <th>rank-5</th>\n",
       "      <th>rank-6</th>\n",
       "      <th>rank-7</th>\n",
       "      <th>rank-8</th>\n",
       "      <th>rank-9</th>\n",
       "      <th>rank-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1142680</td>\n",
       "      <td>38226</td>\n",
       "      <td>17077</td>\n",
       "      <td>71221</td>\n",
       "      <td>61031</td>\n",
       "      <td>62371</td>\n",
       "      <td>47722</td>\n",
       "      <td>25388</td>\n",
       "      <td>68448</td>\n",
       "      <td>26772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>31090</td>\n",
       "      <td>43629</td>\n",
       "      <td>5359</td>\n",
       "      <td>31095</td>\n",
       "      <td>36295</td>\n",
       "      <td>40499</td>\n",
       "      <td>42198</td>\n",
       "      <td>1511</td>\n",
       "      <td>30450</td>\n",
       "      <td>56230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>38677</td>\n",
       "      <td>63262</td>\n",
       "      <td>46549</td>\n",
       "      <td>1944</td>\n",
       "      <td>63267</td>\n",
       "      <td>15047</td>\n",
       "      <td>7010</td>\n",
       "      <td>53956</td>\n",
       "      <td>44068</td>\n",
       "      <td>7012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>70257</td>\n",
       "      <td>59694</td>\n",
       "      <td>36602</td>\n",
       "      <td>42322</td>\n",
       "      <td>44232</td>\n",
       "      <td>42318</td>\n",
       "      <td>49395</td>\n",
       "      <td>29277</td>\n",
       "      <td>53986</td>\n",
       "      <td>53001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>46284</td>\n",
       "      <td>12742</td>\n",
       "      <td>34756</td>\n",
       "      <td>60260</td>\n",
       "      <td>46276</td>\n",
       "      <td>60258</td>\n",
       "      <td>12737</td>\n",
       "      <td>12743</td>\n",
       "      <td>64341</td>\n",
       "      <td>46283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>266</td>\n",
       "      <td>62053</td>\n",
       "      <td>63693</td>\n",
       "      <td>39597</td>\n",
       "      <td>47317</td>\n",
       "      <td>7091</td>\n",
       "      <td>62046</td>\n",
       "      <td>45772</td>\n",
       "      <td>35333</td>\n",
       "      <td>11605</td>\n",
       "      <td>35885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>271</td>\n",
       "      <td>42603</td>\n",
       "      <td>41719</td>\n",
       "      <td>71460</td>\n",
       "      <td>42604</td>\n",
       "      <td>19146</td>\n",
       "      <td>28528</td>\n",
       "      <td>59641</td>\n",
       "      <td>1911</td>\n",
       "      <td>27691</td>\n",
       "      <td>32929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>275</td>\n",
       "      <td>13048</td>\n",
       "      <td>13300</td>\n",
       "      <td>64172</td>\n",
       "      <td>56340</td>\n",
       "      <td>32937</td>\n",
       "      <td>62478</td>\n",
       "      <td>58869</td>\n",
       "      <td>41825</td>\n",
       "      <td>24045</td>\n",
       "      <td>25105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>279</td>\n",
       "      <td>33367</td>\n",
       "      <td>23615</td>\n",
       "      <td>53312</td>\n",
       "      <td>14397</td>\n",
       "      <td>8514</td>\n",
       "      <td>32130</td>\n",
       "      <td>14401</td>\n",
       "      <td>71242</td>\n",
       "      <td>10359</td>\n",
       "      <td>64798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>286</td>\n",
       "      <td>20111</td>\n",
       "      <td>13716</td>\n",
       "      <td>21618</td>\n",
       "      <td>13715</td>\n",
       "      <td>21609</td>\n",
       "      <td>72346</td>\n",
       "      <td>434</td>\n",
       "      <td>0</td>\n",
       "      <td>44924</td>\n",
       "      <td>20130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    query-id   rank-1  rank-2  rank-3  rank-4  rank-5  rank-6  rank-7  rank-8  \\\n",
       "0          3  1142680   38226   17077   71221   61031   62371   47722   25388   \n",
       "1          4    31090   43629    5359   31095   36295   40499   42198    1511   \n",
       "2          5    38677   63262   46549    1944   63267   15047    7010   53956   \n",
       "3          6    70257   59694   36602   42322   44232   42318   49395   29277   \n",
       "4          8    46284   12742   34756   60260   46276   60258   12737   12743   \n",
       "..       ...      ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "95       266    62053   63693   39597   47317    7091   62046   45772   35333   \n",
       "96       271    42603   41719   71460   42604   19146   28528   59641    1911   \n",
       "97       275    13048   13300   64172   56340   32937   62478   58869   41825   \n",
       "98       279    33367   23615   53312   14397    8514   32130   14401   71242   \n",
       "99       286    20111   13716   21618   13715   21609   72346     434       0   \n",
       "\n",
       "    rank-9  rank-10  \n",
       "0    68448    26772  \n",
       "1    30450    56230  \n",
       "2    44068     7012  \n",
       "3    53986    53001  \n",
       "4    64341    46283  \n",
       "..     ...      ...  \n",
       "95   11605    35885  \n",
       "96   27691    32929  \n",
       "97   24045    25105  \n",
       "98   10359    64798  \n",
       "99   44924    20130  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "predictions_to_ids_ranking(corpus2,queries2,predict_documents(tfidf, vectors, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1e9159-5674-490c-88fb-c25d0df96cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
