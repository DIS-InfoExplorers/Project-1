{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb84fe67-47e4-4027-a1d4-9eec3906ff8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:41.089322400Z",
     "start_time": "2023-10-20T21:56:35.790737200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim import downloader as api\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182ee2e-3277-4844-9174-b9729bd536c8",
   "metadata": {},
   "source": [
    "## Data Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6501acf-b8b7-43fc-91f6-6a0233f345a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:45.333005900Z",
     "start_time": "2023-10-20T21:56:41.088329200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         corpus-id                                               text\n0                0  The presence of communication amid scientific ...\n1                8  In June 1942, the United States Army Corps of ...\n2               12  Tutorial: Introduction to Restorative Justice....\n3               16  The approach is based on a theory of justice t...\n4               23  Phloem is a conductive (or vascular) tissue fo...\n...            ...                                                ...\n1471401    8841780  Wolves don't hide. They don't even live in cav...\n1471402    8841787  The UNHCR Country Representative in Kenya. Str...\n1471403    8841790  2. Describe the misery at Kakuma. 3. Compariso...\n1471404    8841800  Following the death of his employer and mentor...\n1471405    8841801  Presently, Puerto Rico holds the most titles f...\n\n[1471406 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>corpus-id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>The presence of communication amid scientific ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>In June 1942, the United States Army Corps of ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12</td>\n      <td>Tutorial: Introduction to Restorative Justice....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16</td>\n      <td>The approach is based on a theory of justice t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23</td>\n      <td>Phloem is a conductive (or vascular) tissue fo...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1471401</th>\n      <td>8841780</td>\n      <td>Wolves don't hide. They don't even live in cav...</td>\n    </tr>\n    <tr>\n      <th>1471402</th>\n      <td>8841787</td>\n      <td>The UNHCR Country Representative in Kenya. Str...</td>\n    </tr>\n    <tr>\n      <th>1471403</th>\n      <td>8841790</td>\n      <td>2. Describe the misery at Kakuma. 3. Compariso...</td>\n    </tr>\n    <tr>\n      <th>1471404</th>\n      <td>8841800</td>\n      <td>Following the death of his employer and mentor...</td>\n    </tr>\n    <tr>\n      <th>1471405</th>\n      <td>8841801</td>\n      <td>Presently, Puerto Rico holds the most titles f...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1471406 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_json('data/corpus.jsonl', lines=True).sort_values(by=[\"_id\"]).rename(\n",
    "    columns={\"_id\": \"corpus-id\"}).reset_index(drop=True)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a717db0-efa2-4626-bf05-45ed2aad82b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:47.028648100Z",
     "start_time": "2023-10-20T21:56:45.331902100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      query-id                                               text\n0       300674  how many years did william bradford serve as g...\n1       125705                                  define preventive\n2        94798                            color overlay photoshop\n3         9083  ____________________ is considered the father ...\n4       174249  does xpress bet charge to deposit money in you...\n...        ...                                                ...\n7432    147073  difference between discrete and process manufa...\n7433    243761                 how long did abraham lincoln serve\n7434    162662       does adult acne rosacea give you blepharitis\n7435    247194                       how long do you bake muffins\n7436    195199                                     glioma meaning\n\n[7437 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query-id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>300674</td>\n      <td>how many years did william bradford serve as g...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>125705</td>\n      <td>define preventive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>94798</td>\n      <td>color overlay photoshop</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9083</td>\n      <td>____________________ is considered the father ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>174249</td>\n      <td>does xpress bet charge to deposit money in you...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7432</th>\n      <td>147073</td>\n      <td>difference between discrete and process manufa...</td>\n    </tr>\n    <tr>\n      <th>7433</th>\n      <td>243761</td>\n      <td>how long did abraham lincoln serve</td>\n    </tr>\n    <tr>\n      <th>7434</th>\n      <td>162662</td>\n      <td>does adult acne rosacea give you blepharitis</td>\n    </tr>\n    <tr>\n      <th>7435</th>\n      <td>247194</td>\n      <td>how long do you bake muffins</td>\n    </tr>\n    <tr>\n      <th>7436</th>\n      <td>195199</td>\n      <td>glioma meaning</td>\n    </tr>\n  </tbody>\n</table>\n<p>7437 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = pd.read_json(path_or_buf='data/queries.jsonl', lines=True)\n",
    "queries['text'] = queries['text'].str.strip()\n",
    "queries = queries.drop(columns=[\"metadata\"]).rename(columns={\"_id\": \"query-id\"})\n",
    "queries\n",
    "\n",
    "df_test = pd.read_csv(\"data/task1_test.tsv\", sep=\"\\t\")\n",
    "queries_test = pd.merge(queries, df_test, left_on='query-id', right_on='query-id', how='inner').drop(columns=[\"id\"])\n",
    "\n",
    "##Free queries\n",
    "queries = None\n",
    "\n",
    "queries_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7684f19-5008-441e-92d9-8b40b82fa697",
   "metadata": {},
   "source": [
    "### Importing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ec46f3-32ca-4f2e-bd2f-f8865fb50e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:47.174180400Z",
     "start_time": "2023-10-20T21:56:47.018344100Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model = KeyedVectors.load('data/glove.model.d2v')\n",
    "except:\n",
    "    print(\"404, Now Fetching Model ...\")\n",
    "    model = api.load(\"glove-wiki-gigaword-50\")\n",
    "    model.save('data/glove.model.d2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67a3f68-6889-46e7-a29e-3a6b4b73ca6e",
   "metadata": {},
   "source": [
    "### Prepare text processing constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb3c8bc-0585-4807-b4d2-8f161e0fdef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:47.176353400Z",
     "start_time": "2023-10-20T21:56:47.164103900Z"
    }
   },
   "outputs": [],
   "source": [
    "STEMMER = PorterStemmer()\n",
    "NON_ASCII_PATTERN = re.compile(r'\\\\u[0-9a-fA-F]{4}')\n",
    "STOPWORDS_SET = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d943715b-bb22-4a31-9f7a-47f07e4ca41d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:47.180021200Z",
     "start_time": "2023-10-20T21:56:47.175739800Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the given text by performing several operations:\n",
    "    1. Converts the text to lowercase.\n",
    "    2. Removes non-ASCII characters.\n",
    "    3. Replaces punctuation with spaces.\n",
    "    4. Removes digits.\n",
    "    5. Tokenizes the text using NLTK's word_tokenize.\n",
    "    6. Removes stopwords and stems the words using PorterStemmer.\n",
    "    7. Filters out words that are not in the model vocabulary.\n",
    "    \n",
    "    Args:\n",
    "    - text (str): The input text to preprocess.\n",
    "\n",
    "    Returns:\n",
    "    - list of str: A list of preprocessed and tokenized words.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = NON_ASCII_PATTERN.sub('', text)\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n",
    "    text = text.translate(str.maketrans('', '', string.digits))\n",
    "\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [STEMMER.stem(word) for word in words if word not in STOPWORDS_SET and word in model]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56711ff3-28ef-44de-9a21-7a8dd799251d",
   "metadata": {},
   "source": [
    "##  TF-IDF Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6169b048-bf5d-4f73-bd58-cb7c28eec053",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:47.237380100Z",
     "start_time": "2023-10-20T21:56:47.205899600Z"
    }
   },
   "outputs": [],
   "source": [
    "def populate_tfidf_dataframe_sparse(documents, vocabulary):\n",
    "    \"\"\"\n",
    "    Generates a term frequency (TF) matrix for the given documents and vocabulary.\n",
    "\n",
    "    Args:\n",
    "    - documents (list of list of str): The preprocessed documents represented as lists of words.\n",
    "    - vocabulary (list of str): The unique words to be considered from all documents.\n",
    "\n",
    "    Returns:\n",
    "    - lil_matrix: A sparse matrix representation of the term frequencies.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a sparse matrix to hold the term frequencies\n",
    "    tf_matrix = lil_matrix((len(documents), len(vocabulary)), dtype=int)\n",
    "\n",
    "    # Map each word in the vocabulary to its column index for faster lookup\n",
    "    vocab_index_map = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "\n",
    "    for i, doc in enumerate(documents):\n",
    "        for word in doc:\n",
    "            if word in vocab_index_map:\n",
    "                tf_matrix[i, vocab_index_map[word]] += 1\n",
    "\n",
    "    return tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9195aae4-7e3c-4efc-b9e1-b20c5e65cf24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:47.239450200Z",
     "start_time": "2023-10-20T21:56:47.208518900Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfidf(corpus_text):\n",
    "    \"\"\"\n",
    "    Computes the Term Frequency-Inverse Document Frequency (TF-IDF) matrix for the given corpus.\n",
    "\n",
    "    Args:\n",
    "    - corpus_text (iterable): The input corpus where each item is a raw text document.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the following:\n",
    "        1. documents (list of list of str): Preprocessed documents.\n",
    "        2. tfidf_matrix (csr_matrix): The computed TF-IDF matrix.\n",
    "        3. vocabulary (list of str): The vocabulary extracted from the corpus.\n",
    "        4. idf (numpy array): The computed inverse document frequencies for each word in the vocabulary.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Process docs ...\")\n",
    "    documents = corpus_text.progress_apply(lambda x: preprocess_text(x))\n",
    "\n",
    "    print(\"Create vocab ...\")\n",
    "    vocabulary = list(set(word for doc in documents for word in doc))\n",
    "    vocabulary.sort()\n",
    "\n",
    "    print(\"Compute tf ...\")\n",
    "    tf_matrix = populate_tfidf_dataframe_sparse(documents, vocabulary)\n",
    "\n",
    "    print(\"Compute idf ...\")\n",
    "    doc_count = len(documents)\n",
    "    df = (tf_matrix > 0).sum(axis=0)\n",
    "    idf = np.log((doc_count + 0.5) / (df + 0.5))\n",
    "\n",
    "    print(\"Compute tf-idf ...\")\n",
    "    tf_matrix = tf_matrix.tocsr()\n",
    "    tf_matrix = tf_matrix.multiply(1 / tf_matrix.sum(axis=1))\n",
    "    tfidf_matrix = tf_matrix.multiply(idf)\n",
    "\n",
    "    print(\"Done!\")\n",
    "    return documents, tfidf_matrix, vocabulary, idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d8219-4390-4102-9099-062b1c54504c",
   "metadata": {},
   "source": [
    "### TF-IDF Corpus Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c69b034b-3c8d-4170-b60d-b33e6cd0fa64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:47.239450200Z",
     "start_time": "2023-10-20T21:56:47.217912900Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfidf_process_corpus():\n",
    "    DATA_FOLDER = \"data/\"\n",
    "    FILE_NAME = \"submission\"\n",
    "    try:\n",
    "        tf_idf = pd.read_pickle(f'{DATA_FOLDER}tfidf-{FILE_NAME}.pkl')\n",
    "        idf = pd.read_pickle(f'{DATA_FOLDER}idf-{FILE_NAME}.pkl')\n",
    "        vocabulary = pd.read_pickle(f'{DATA_FOLDER}vocabulary-{FILE_NAME}.pkl')\n",
    "        documents = pd.read_pickle(f'{DATA_FOLDER}document-{FILE_NAME}.pkl')\n",
    "        return documents, tf_idf, vocabulary, idf\n",
    "    except:\n",
    "        print(\"404, creating required metadata ...\")\n",
    "        documents, tf_idf, vocabulary, idf = tfidf(corpus[\"text\"])\n",
    "\n",
    "        with open(f'{DATA_FOLDER}tfidf-{FILE_NAME}.pkl', 'wb') as f:\n",
    "            pickle.dump(tf_idf, f)\n",
    "\n",
    "        with open(f'{DATA_FOLDER}idf-{FILE_NAME}.pkl', 'wb') as f:\n",
    "            pickle.dump(idf, f)\n",
    "\n",
    "        with open(f'{DATA_FOLDER}vocabulary-{FILE_NAME}.pkl', 'wb') as f:\n",
    "            pickle.dump(vocabulary, f)\n",
    "\n",
    "        with open(f'{DATA_FOLDER}document-{FILE_NAME}.pkl', 'wb') as f:\n",
    "            pickle.dump(documents, f)\n",
    "\n",
    "        return documents, tf_idf, vocabulary, idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e68a6c41-89ca-4c1b-be9a-fceb9be9cc32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:54.824096500Z",
     "start_time": "2023-10-20T21:56:47.223443100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.11 s\n",
      "Wall time: 7.58 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0          [presenc, commun, amid, scientif, mind, equal,...\n 1          [june, unit, state, armi, corp, manhattan, pro...\n 2          [tutori, introduct, restor, justic, restor, ju...\n 3          [approach, base, theori, justic, consid, crime...\n 4          [phloem, conduct, vascular, tissu, found, plan...\n                                  ...                        \n 1471401    [wolv, hide, even, live, cave, live, open, for...\n 1471402    [unhcr, countri, repres, kenya, street, addres...\n 1471403    [describ, miseri, kakuma, comparison, popul, k...\n 1471404    [follow, death, employ, mentor, bumpi, johnson...\n 1471405    [present, puerto, rico, hold, titl, miss, univ...\n Name: text, Length: 1471406, dtype: object,\n <1471406x135442 sparse matrix of type '<class 'numpy.float64'>'\n \twith 34858541 stored elements in COOrdinate format>,\n ['a',\n  'aa',\n  'aaa',\n  'aaaa',\n  'aaaaa',\n  'aaah',\n  'aaahh',\n  'aab',\n  'aaba',\n  'aabb',\n  'aac',\n  'aacc',\n  'aach',\n  'aachen',\n  'aacm',\n  'aacn',\n  'aacr',\n  'aacsb',\n  'aacta',\n  'aad',\n  'aadhi',\n  'aadi',\n  'aadt',\n  'aadu',\n  'aadvantag',\n  'aae',\n  'aaf',\n  'aafc',\n  'aaftc',\n  'aag',\n  'aagaard',\n  'aah',\n  'aaha',\n  'aai',\n  'aaii',\n  'aaj',\n  'aaja',\n  'aak',\n  'aakash',\n  'aaker',\n  'aal',\n  'aalborg',\n  'aalen',\n  'aaliyah',\n  'aalsmeer',\n  'aalto',\n  'aam',\n  'aama',\n  'aamc',\n  'aami',\n  'aamir',\n  'aamodt',\n  'aan',\n  'aana',\n  'aand',\n  'aang',\n  'aani',\n  'aann',\n  'aanr',\n  'aao',\n  'aap',\n  'aapa',\n  'aapb',\n  'aapc',\n  'aapg',\n  'aapk',\n  'aapl',\n  'aapp',\n  'aapt',\n  'aar',\n  'aarabi',\n  'aarau',\n  'aard',\n  'aardman',\n  'aardsma',\n  'aardvark',\n  'aardwolf',\n  'aargau',\n  'aarhu',\n  'aari',\n  'aarn',\n  'aaron',\n  'aaronson',\n  'aarp',\n  'aart',\n  'aarthi',\n  'aarti',\n  'aaru',\n  'aarushi',\n  'aas',\n  'aasa',\n  'aascu',\n  'aasen',\n  'aashiqui',\n  'aashish',\n  'aashto',\n  'aasm',\n  'aastha',\n  'aasu',\n  'aat',\n  'aata',\n  'aati',\n  'aau',\n  'aaup',\n  'aav',\n  'ab',\n  'aba',\n  'abab',\n  'ababa',\n  'abac',\n  'abaca',\n  'abacavir',\n  'abacha',\n  'abaci',\n  'aback',\n  'abaco',\n  'abacu',\n  'abad',\n  'abada',\n  'abadan',\n  'abaddon',\n  'abadi',\n  'abadia',\n  'abaft',\n  'abag',\n  'abagnal',\n  'abah',\n  'abair',\n  'abajo',\n  'abakanowicz',\n  'abala',\n  'abalon',\n  'abam',\n  'aban',\n  'abana',\n  'abandon',\n  'abang',\n  'abani',\n  'abano',\n  'abap',\n  'abar',\n  'abarkuh',\n  'abarth',\n  'abas',\n  'abash',\n  'abasolo',\n  'abassi',\n  'abat',\n  'abattoir',\n  'abawi',\n  'abaxi',\n  'abay',\n  'abaya',\n  'abb',\n  'abba',\n  'abbad',\n  'abbadi',\n  'abbasi',\n  'abbasid',\n  'abbassi',\n  'abbay',\n  'abbess',\n  'abbevil',\n  'abbey',\n  'abbeyleix',\n  'abbi',\n  'abbington',\n  'abbitt',\n  'abbot',\n  'abbotsburi',\n  'abbotsford',\n  'abbott',\n  'abbottabad',\n  'abboud',\n  'abbr',\n  'abbrev',\n  'abbrevi',\n  'abc',\n  'abca',\n  'abcc',\n  'abcd',\n  'abcdefghijklmnopqrstuvwxyz',\n  'abcl',\n  'abco',\n  'abcp',\n  'abd',\n  'abdalla',\n  'abdallah',\n  'abdel',\n  'abdelatif',\n  'abdelaziz',\n  'abdelhamid',\n  'abdelkrim',\n  'abdella',\n  'abdelmalek',\n  'abdelrahman',\n  'abdelsalam',\n  'abdera',\n  'abderhalden',\n  'abdeslam',\n  'abdi',\n  'abdic',\n  'abdin',\n  'abdo',\n  'abdol',\n  'abdollah',\n  'abdomen',\n  'abdomin',\n  'abdomini',\n  'abdon',\n  'abdou',\n  'abdoul',\n  'abdoulay',\n  'abdu',\n  'abducen',\n  'abduct',\n  'abducte',\n  'abductor',\n  'abduh',\n  'abdul',\n  'abdula',\n  'abdulahi',\n  'abdulaziz',\n  'abdulla',\n  'abdullaev',\n  'abdullah',\n  'abdullahi',\n  'abdulmajid',\n  'abdulmutallab',\n  'abdulrahman',\n  'abdur',\n  'abdussalam',\n  'abe',\n  'abeam',\n  'abeba',\n  'abebook',\n  'abecedarian',\n  'abedi',\n  'abedin',\n  'abedini',\n  'abednego',\n  'abeer',\n  'abegweit',\n  'abeil',\n  'abel',\n  'abela',\n  'abelard',\n  'abelardo',\n  'abelia',\n  'abelian',\n  'abelisaurid',\n  'abella',\n  'abellio',\n  'abello',\n  'abelson',\n  'aben',\n  'abenaki',\n  'abend',\n  'abengoa',\n  'abeokuta',\n  'abequa',\n  'aber',\n  'aberconwi',\n  'abercorn',\n  'abercrombi',\n  'abercynon',\n  'aberdar',\n  'aberdeen',\n  'aberdeenshir',\n  'aberdour',\n  'aberfeldi',\n  'aberfoyl',\n  'abergavenni',\n  'abergel',\n  'aberlin',\n  'abern',\n  'abernathi',\n  'abernethi',\n  'aberr',\n  'aberra',\n  'abert',\n  'aberystwyth',\n  'abet',\n  'abettor',\n  'abey',\n  'abf',\n  'abg',\n  'abgeordnetenhau',\n  'abh',\n  'abha',\n  'abhainn',\n  'abhandlungen',\n  'abhay',\n  'abhaya',\n  'abhi',\n  'abhidhamma',\n  'abhijeet',\n  'abhijit',\n  'abhik',\n  'abhimanyu',\n  'abhinav',\n  'abhinavagupta',\n  'abhishek',\n  'abhor',\n  'abhorr',\n  'abi',\n  'abia',\n  'abian',\n  'abib',\n  'abid',\n  'abidin',\n  'abidjan',\n  'abierto',\n  'abigail',\n  'abijah',\n  'abil',\n  'abila',\n  'abildgaard',\n  'abilen',\n  'abilifi',\n  'abilio',\n  'abim',\n  'abimbola',\n  'abin',\n  'abing',\n  'abingdon',\n  'abington',\n  'abiogen',\n  'abiogenesi',\n  'abiola',\n  'abiom',\n  'abiot',\n  'abiquiu',\n  'abir',\n  'abisko',\n  'abit',\n  'abita',\n  'abitibi',\n  'abitur',\n  'abjad',\n  'abject',\n  'abjectli',\n  'abjur',\n  'abkhazia',\n  'abl',\n  'abla',\n  'ablat',\n  'ablaut',\n  'ablaz',\n  'ableman',\n  'abler',\n  'ableton',\n  'ablett',\n  'abli',\n  'abloom',\n  'abloy',\n  'ablut',\n  'abm',\n  'abn',\n  'abneg',\n  'abner',\n  'abnett',\n  'abney',\n  'abnorm',\n  'abnt',\n  'abo',\n  'aboard',\n  'abod',\n  'abogado',\n  'abolfazl',\n  'abolish',\n  'abolit',\n  'abolition',\n  'abolitionist',\n  'abomin',\n  'abond',\n  'abor',\n  'aborigin',\n  'aborn',\n  'abort',\n  'abortifaci',\n  'abortionist',\n  'abot',\n  'abott',\n  'abou',\n  'aboubakar',\n  'aboukir',\n  'abound',\n  'about',\n  'aboutaleb',\n  'aboveground',\n  'abovement',\n  'abp',\n  'abpp',\n  'abq',\n  'abqaiq',\n  'abr',\n  'abra',\n  'abraaj',\n  'abracadabra',\n  'abrad',\n  'abraha',\n  'abraham',\n  'abrahamian',\n  'abrahamowicz',\n  'abrahamson',\n  'abrahamsson',\n  'abram',\n  'abramoff',\n  'abramov',\n  'abramovich',\n  'abramowicz',\n  'abramowitz',\n  'abramski',\n  'abramson',\n  'abrant',\n  'abrar',\n  'abras',\n  'abravanel',\n  'abraxa',\n  'abraxan',\n  'abrazo',\n  'abreast',\n  'abrego',\n  'abren',\n  'abreu',\n  'abri',\n  'abric',\n  'abridg',\n  'abriel',\n  'abrikosov',\n  'abril',\n  'abrir',\n  'abroad',\n  'abrog',\n  'abrolho',\n  'abron',\n  'abrupt',\n  'abruptli',\n  'abruzzes',\n  'abruzzi',\n  'abruzzo',\n  'absa',\n  'absalom',\n  'absalon',\n  'absaroka',\n  'abscam',\n  'abscess',\n  'abscis',\n  'absciss',\n  'abscissa',\n  'abscond',\n  'absecon',\n  'abseil',\n  'absenc',\n  'absens',\n  'absent',\n  'absente',\n  'absentia',\n  'absher',\n  'absheron',\n  'abshir',\n  'absinth',\n  'absinthium',\n  'absolom',\n  'absolut',\n  'absolutepunk',\n  'absolutist',\n  'absoluto',\n  'absolv',\n  'absorb',\n  'absorpt',\n  'abssi',\n  'abstain',\n  'abstemi',\n  'abstent',\n  'abstin',\n  'abstract',\n  'abstraction',\n  'abstractionist',\n  'abstractli',\n  'abstrus',\n  'absurd',\n  'absurdist',\n  'absurdistan',\n  'absurdli',\n  'absurdum',\n  'abt',\n  'abta',\n  'abtahi',\n  'abteilung',\n  'abu',\n  'abubakar',\n  'abudu',\n  'abuela',\n  'abuelo',\n  'abuja',\n  'abul',\n  'abuna',\n  'abund',\n  'abunda',\n  'abundantli',\n  'aburi',\n  'abus',\n  'abut',\n  'abutilon',\n  'abuzz',\n  'abv',\n  'abvp',\n  'abw',\n  'abwehr',\n  'abx',\n  'abyan',\n  'abydo',\n  'abyei',\n  'abysm',\n  'abyss',\n  'abyssinia',\n  'abyssinian',\n  'abyssinica',\n  'abz',\n  'abzug',\n  'ac',\n  'aca',\n  'acac',\n  'acacia',\n  'acacio',\n  'acad',\n  'academ',\n  'academi',\n  'academia',\n  'academica',\n  'academician',\n  'acadi',\n  'acadia',\n  'acadian',\n  'acadiana',\n  'acadien',\n  'acai',\n  'acala',\n  'acalypha',\n  'acampros',\n  'acan',\n  'acanthacea',\n  'acanthamoeba',\n  'acanthosi',\n  'acanthostega',\n  'acanthu',\n  'acap',\n  'acapella',\n  'acappella',\n  'acapulco',\n  'acar',\n  'acara',\n  'acarbos',\n  'acari',\n  'acarida',\n  'acasta',\n  'acat',\n  'acauli',\n  'acb',\n  'acbar',\n  'acbl',\n  'acbsp',\n  'acc',\n  'acca',\n  'accademia',\n  'accardo',\n  'accc',\n  'acccord',\n  'acced',\n  'accel',\n  'acceler',\n  'accelerando',\n  'acceleromet',\n  'accent',\n  'accentor',\n  'accentu',\n  'accentur',\n  'accept',\n  'acceptor',\n  'acceso',\n  'access',\n  'accessor',\n  'accessori',\n  'accetta',\n  'acci',\n  'accid',\n  'accident',\n  'accio',\n  'accion',\n  'acciona',\n  'accipit',\n  'accipitrida',\n  'acclaim',\n  'acclam',\n  'acclim',\n  'acclimat',\n  'acclimatis',\n  'acco',\n  'accokeek',\n  'accol',\n  'accola',\n  'accolad',\n  'accomac',\n  'accomack',\n  'accommod',\n  'accomod',\n  'accompani',\n  'accompanist',\n  'accompli',\n  'accomplic',\n  'accomplish',\n  'accor',\n  'accord',\n  'accordian',\n  'accordingli',\n  'accordion',\n  'accordionist',\n  'accost',\n  'account',\n  'accountemp',\n  'accounthold',\n  'accouter',\n  'accoutr',\n  'accp',\n  'accra',\n  'accredit',\n  'accreditor',\n  'accret',\n  'accretionari',\n  'accrington',\n  'accross',\n  'accru',\n  'accrual',\n  'acct',\n  'accu',\n  'accultur',\n  'accum',\n  'accumben',\n  'accumul',\n  'accur',\n  'accuraci',\n  'accurs',\n  'accus',\n  'accusatori',\n  'accusingli',\n  'accustom',\n  'accutan',\n  'accuweath',\n  'acd',\n  'acda',\n  'acdc',\n  'acdelco',\n  'ace',\n  'acea',\n  'acec',\n  'aceh',\n  'acei',\n  'acela',\n  'acellular',\n  'acep',\n  'acer',\n  'acerb',\n  'acerca',\n  'acero',\n  'acess',\n  'acesulfam',\n  'acet',\n  'acetabular',\n  'acetabulum',\n  'acetaldehyd',\n  'acetaminophen',\n  'acetazolamid',\n  'aceto',\n  'acetoacet',\n  'acetobact',\n  'acetoin',\n  'aceton',\n  'acetonid',\n  'acetonitril',\n  'acetophenon',\n  'acetosa',\n  'acetosella',\n  'acetyl',\n  'acetylaceton',\n  'acetylcholin',\n  'acetylcholinesteras',\n  'acetylcystein',\n  'acetylen',\n  'acetylid',\n  'acetylsalicyl',\n  'acetyltransferas',\n  'acev',\n  'acevedo',\n  'acey',\n  'acf',\n  'acg',\n  'acgm',\n  'ach',\n  'acha',\n  'achaea',\n  'achaean',\n  'achaemenian',\n  'achaemenid',\n  'achaia',\n  'achala',\n  'achalasia',\n  'achan',\n  'achanta',\n  'achar',\n  'acharya',\n  'achat',\n  'achatina',\n  'acheampong',\n  'acheb',\n  'acheiv',\n  'achel',\n  'acheloo',\n  'achen',\n  'achenbach',\n  'achern',\n  'acheron',\n  'acheson',\n  'acheulean',\n  'acheulian',\n  'achi',\n  'achiev',\n  'achieva',\n  'achil',\n  'achillea',\n  'achilleo',\n  'achilleu',\n  'achim',\n  'achimota',\n  'achin',\n  'achingli',\n  'achiot',\n  'achir',\n  'achl',\n  'achm',\n  'acho',\n  'acholi',\n  'achon',\n  'achondrit',\n  'achondroplasia',\n  'achr',\n  'achrafieh',\n  'achromat',\n  'achromatopsia',\n  'achterhoek',\n  'achtung',\n  'achu',\n  'achuar',\n  'achuthanandan',\n  'aci',\n  'acia',\n  'acic',\n  'aciclovir',\n  'acicular',\n  'acid',\n  'acidemia',\n  'acidif',\n  'acidifi',\n  'acidophil',\n  'acidophilu',\n  'acidosi',\n  'acidul',\n  'aciduria',\n  'aciliu',\n  'acim',\n  'aciman',\n  'acinar',\n  'acinetobact',\n  'acinonyx',\n  'acip',\n  'acipens',\n  'acireal',\n  'acit',\n  'acj',\n  'ack',\n  'ackbar',\n  'acke',\n  'acker',\n  'ackerli',\n  'ackerman',\n  'ackermann',\n  'ackl',\n  'acklam',\n  'ackland',\n  'ackley',\n  'acklin',\n  'ackman',\n  'acknowledg',\n  'acknowleg',\n  'ackoff',\n  'ackroyd',\n  'ackworth',\n  'acl',\n  'aclara',\n  'aclj',\n  'aclu',\n  'acm',\n  'acma',\n  'acmi',\n  'acn',\n  'acna',\n  'aco',\n  'acog',\n  'acol',\n  'acolyt',\n  'acom',\n  'acoma',\n  'acomb',\n  'acon',\n  'aconcagua',\n  'aconit',\n  'aconitum',\n  'acord',\n  'acorda',\n  'acorn',\n  'acoru',\n  'acosta',\n  'acount',\n  'acoust',\n  'acp',\n  'acpa',\n  'acpi',\n  'acpo',\n  'acq',\n  'acqua',\n  'acquaint',\n  'acquaintanceship',\n  'acquaviva',\n  'acqui',\n  'acquiesc',\n  'acquir',\n  'acquisit',\n  'acquist',\n  'acquit',\n  'acquitt',\n  'acr',\n  'acra',\n  'acral',\n  'acreag',\n  'acri',\n  'acrid',\n  'acridida',\n  'acridin',\n  'acrimoni',\n  'acrisiu',\n  'acrl',\n  'acro',\n  'acrobat',\n  'acrolein',\n  'acromegali',\n  'acromion',\n  'acronicta',\n  'acronym',\n  'acrophobia',\n  'acropoli',\n  'acropora',\n  'acrosom',\n  'across',\n  'acrost',\n  'acryl',\n  'acrylamid',\n  'acrylonitril',\n  'acsa',\n  'acsi',\n  'acsm',\n  'acss',\n  'act',\n  'acta',\n  'actaea',\n  'actaeon',\n  'actavi',\n  'actblu',\n  'actc',\n  'actel',\n  'actelion',\n  'acth',\n  'actin',\n  'actinid',\n  'actinidia',\n  'actinidiacea',\n  'actinium',\n  'actinobacteria',\n  'actinolit',\n  'actinomorph',\n  'actinomyc',\n  'actinomycet',\n  'actio',\n  'action',\n  'actionaid',\n  'actionscript',\n  'actiq',\n  'actitud',\n  'actium',\n  'activ',\n  'activa',\n  'activas',\n  'activesync',\n  'activewear',\n  'activex',\n  'activia',\n  'actividad',\n  'activis',\n  'activist',\n  'activit',\n  'acto',\n  'acton',\n  'actonel',\n  'actor',\n  'actress',\n  'actu',\n  'actua',\n  'actual',\n  'actualidad',\n  'actualment',\n  'actuar',\n  'actuari',\n  'actuat',\n  'actuel',\n  'actv',\n  'acu',\n  'acuerdo',\n  'acuff',\n  'acuiti',\n  'aculeata',\n  'aculeatu',\n  'acum',\n  'acumen',\n  'acumin',\n  'acuminata',\n  'acuminatum',\n  'acuna',\n  'acupoint',\n  'acupressur',\n  'acupunctur',\n  'acupuncturist',\n  'acura',\n  'acushnet',\n  'acut',\n  'acuta',\n  'acutu',\n  'acuvu',\n  'acv',\n  'acw',\n  'acwf',\n  'acworth',\n  'acx',\n  'acxiom',\n  'acycl',\n  'acyclovir',\n  'acyl',\n  'acyltransferas',\n  'ad',\n  'ada',\n  'adab',\n  'adac',\n  'adachi',\n  'adad',\n  'adado',\n  'adag',\n  'adagio',\n  'adah',\n  'adai',\n  'adair',\n  'adairsvil',\n  'adak',\n  'adal',\n  'adalah',\n  'adalat',\n  'adalbert',\n  'adalberto',\n  'adalet',\n  'adalgisa',\n  'adalia',\n  'adalid',\n  'adalimumab',\n  'adalin',\n  'adam',\n  'adama',\n  'adamantan',\n  'adamantin',\n  'adamantium',\n  'adamantli',\n  'adamawa',\n  'adamczyk',\n  'adament',\n  'adaminabi',\n  'adamo',\n  'adamski',\n  'adamson',\n  'adamstown',\n  'adamsvil',\n  'adan',\n  'adana',\n  'adang',\n  ...],\n matrix([[ 8.85700556,  7.40211618,  7.94886249, ..., 11.52758065,\n          13.7962642 , 12.69765191]]))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_process_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c188dd49-843b-4cf9-80ea-4db4c43a00d0",
   "metadata": {},
   "source": [
    "### TF-IDF Query Processing & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a61123f4-3b40-486c-9da3-5bfa1e717171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:54.835645300Z",
     "start_time": "2023-10-20T21:56:54.826494100Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfidf_vectorize_queries(queries_df, vocabulary, idf):\n",
    "    \"\"\"Convert each query in the DataFrame into its TF-IDF vector.\"\"\"\n",
    "\n",
    "    print(\"Process queries ...\")\n",
    "    # Preprocess all queries\n",
    "    queries_df['processed'] = queries_df['text'].apply(preprocess_text)\n",
    "\n",
    "    print(\"Initialize sparse matrix ...\")\n",
    "    num_queries = len(queries_df)\n",
    "    num_terms = len(vocabulary)\n",
    "\n",
    "    # Using a dictionary for term index lookup\n",
    "    vocab_dict = {term: index for index, term in enumerate(vocabulary)}\n",
    "    tf_matrix = lil_matrix((num_queries, num_terms))\n",
    "\n",
    "    print(\"Compute  tf ...\")\n",
    "    # Populate the sparse matrix\n",
    "    for idx, row in queries_df.iterrows():\n",
    "        for term in row['processed']:\n",
    "            if term in vocab_dict:\n",
    "                tf_matrix[idx, vocab_dict[term]] += 1\n",
    "\n",
    "    print(\"Multiply by idf ...\")\n",
    "    # Convert to CSR format for efficient multiplication and transform TFs to TF-IDF\n",
    "    tfidf_matrix = (tf_matrix.tocsr()).multiply(idf)\n",
    "\n",
    "    print(\"Done !\")\n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc26491-b76f-4bd0-8bbf-21be5b0b4497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:54.902994100Z",
     "start_time": "2023-10-20T21:56:54.829821600Z"
    }
   },
   "outputs": [],
   "source": [
    "def top_k_indices_sparse(matrix: csr_matrix, k: int):\n",
    "    \"\"\"Get top k indices for each row of a sparse matrix.\"\"\"\n",
    "\n",
    "    # Placeholder list for top k indices for each row\n",
    "    top_indices = []\n",
    "\n",
    "    # Iterate over each row\n",
    "    print('Iterate over each row ...')\n",
    "    for i in range(matrix.shape[0]):\n",
    "        row_data = matrix.data[matrix.indptr[i]:matrix.indptr[i + 1]]\n",
    "        row_indices = matrix.indices[matrix.indptr[i]:matrix.indptr[i + 1]]\n",
    "\n",
    "        if len(row_data) < k:\n",
    "            top_indices.append(row_indices)\n",
    "        else:\n",
    "            # Sort the row data and get top k indices\n",
    "            sorted_indices = np.argsort(-row_data)\n",
    "            top_indices.append(row_indices[sorted_indices[:k]])\n",
    "\n",
    "\n",
    "    return top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c67d459-c5be-4d40-a726-143970e9edd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:54.902994100Z",
     "start_time": "2023-10-20T21:56:54.848454500Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfidf_predict_documents(tfidf_matrix_normalized, query_vectors, k):\n",
    "    \"\"\"Process multiple queries and return ranked document indices for each query.\"\"\"\n",
    "\n",
    "    # Compute cosine similarities using matrix operations\n",
    "    print(\"Compute cosine similarities ...\")\n",
    "    similarity_matrix = cosine_similarity(query_vectors, tfidf_matrix_normalized, dense_output=False)\n",
    "\n",
    "    # Get document indices ranked by relevance for each query\n",
    "    print(\"Rank documents ...\")\n",
    "    # print(similarity_matrix.shape)\n",
    "    # ranked_doc_indices = np.argsort(-similarity_matrix)[:, :k]\n",
    "    ranked_doc_indices = top_k_indices_sparse(similarity_matrix, k)\n",
    "\n",
    "    return ranked_doc_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "716fffe9-ddfe-4228-ba45-999b4f693b22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:54.928155Z",
     "start_time": "2023-10-20T21:56:54.856951100Z"
    }
   },
   "outputs": [],
   "source": [
    "def predictions_to_ids_ranking(corpus, queries, prediction):\n",
    "    # Map the prediction rows to the corresponding 'corpus-id' values from the corpus\n",
    "    mapped_results = [corpus.iloc[row]['corpus-id'].values.tolist() for row in prediction]\n",
    "\n",
    "    # Create a DataFrame with 'id', 'corpus-id', and 'score' columns\n",
    "    df = pd.DataFrame({\n",
    "        'id': queries['query-id'].iloc[:len(mapped_results)],\n",
    "        'corpus-id': mapped_results,\n",
    "        'score': [-1 for _ in range(len(mapped_results))]\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020b82fc-dab5-476a-90eb-c0ce2f6fff35",
   "metadata": {},
   "source": [
    "### Deep Embedder Corpus Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7e3632d-3fab-4b1d-898a-f2c1fa2373e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:54.928155Z",
     "start_time": "2023-10-20T21:56:54.866463500Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_pretrained_embedder():\n",
    "    try:\n",
    "        with open('DeepEmbedder.pkl', 'rb') as f:\n",
    "            deep_embedder = pickle.load(f)\n",
    "        return deep_embedder\n",
    "    except:\n",
    "        print('404, Fetching DeepEmbedder')\n",
    "        deep_embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        with open(f'DeepEmbedder.pkl', 'wb') as f:\n",
    "            pickle.dump(deep_embedder, f)\n",
    "        return deep_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf937e7d-bd09-4dae-9d62-68804e3ad2e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:55.049854200Z",
     "start_time": "2023-10-20T21:56:54.871955100Z"
    }
   },
   "outputs": [],
   "source": [
    "DEEP_EMBEDDER = load_pretrained_embedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41a0d7a1-7916-4e06-a55d-e2362c462c7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:55.060455300Z",
     "start_time": "2023-10-20T21:56:55.051775900Z"
    }
   },
   "outputs": [],
   "source": [
    "def deep_embedder_process_corpus():\n",
    "    try:\n",
    "        with open('data/vectorized_corpus-001.pkl', 'rb') as f:\n",
    "            embedded_corpus = pickle.load(f)\n",
    "        return embedded_corpus\n",
    "    except:\n",
    "        print('404, Computing Embeded Corpus ...')\n",
    "        embedded_corpus = DEEP_EMBEDDER.encode(sentences=corpus[\"text\"].tolist(),\n",
    "                                               batch_size=500,  # TO BE CHANGED\n",
    "                                               show_progress_bar=True,\n",
    "                                               device='cpu',  # TO BE CHANGED -- 'cpu', 'cuda', automatic if None\n",
    "                                               )\n",
    "\n",
    "        with open(f'data/vectorized_corpus-001.pkl', 'wb') as f:\n",
    "            pickle.dump(embedded_corpus, f)\n",
    "        return embedded_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35a796a-5fa0-4176-9460-92b4931a8f50",
   "metadata": {},
   "source": [
    "### Deep Embedder Query Processing & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8237bc28-6a5e-4ec9-a401-1b76c66a8510",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:56:55.070463700Z",
     "start_time": "2023-10-20T21:56:55.055486300Z"
    }
   },
   "outputs": [],
   "source": [
    "def deep_vectorize_queries(queries):\n",
    "    return DEEP_EMBEDDER.encode(queries.text.tolist(),\n",
    "                                batch_size=500,  # TO BE CHANGED \n",
    "                                show_progress_bar=True,\n",
    "                                device='cpu',  # TO BE CHANGED -- 'cpu', 'cuda', automatic if None\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "844cda11-52d8-4d6b-8ec5-653c2179a7e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T22:18:35.994360600Z",
     "start_time": "2023-10-20T22:18:35.951928200Z"
    }
   },
   "outputs": [],
   "source": [
    "def deep_predict_documents(top_large_k, vectorized_queries, vectorized_corpus):\n",
    "    # 2D Array for storing indices to relevant documents\n",
    "    # Shape (Number of queries, k)\n",
    "    top_10 = np.zeros((vectorized_queries.shape[0], 10))\n",
    "\n",
    "    # Iterate through each query embedding\n",
    "    for idx, vector_query in enumerate(vectorized_queries):\n",
    "        # Index the embedding of relevant candidates\n",
    "        # Shape of sentence_feature: (large_k, 384)\n",
    "        sentence_feature = vectorized_corpus.loc[top_large_k[idx]]  \n",
    "\n",
    "        # Dot product (numerator of cosine similarity), similar to linear_kernel\n",
    "        similarity = sentence_feature @ vector_query\n",
    "\n",
    "        # Get indices of top-k highest similarities\n",
    "        top_10[idx] = np.argsort(similarity)[-10:]\n",
    "    return top_10.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afe635869b7f99f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T21:57:59.003875400Z",
     "start_time": "2023-10-20T21:56:55.071463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process queries ...\n",
      "Initialize sparse matrix ...\n",
      "Compute  tf ...\n",
      "Multiply by idf ...\n",
      "Done !\n",
      "Compute cosine similarities ...\n",
      "Rank documents ...\n",
      "Iterate over each row ...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/15 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb77c86cde1f4ab7a9f844a4c10b6413"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.9 s\n",
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[7067032, 2495755, 4107182, ..., 4896294, 6127776, 4462214],\n       [7589362, 4935191, 7067056, ..., 4790728, 3068332, 3638484],\n       [1263956, 7067179, 1440567, ..., 5463056, 1744650, 4467321],\n       ...,\n       [2599274, 7140272,    1023, ..., 8365635, 8123759,  822470],\n       [6017132, 6417190, 5990580, ..., 3116123, 3297396, 5258892],\n       [7136754, 6001369, 6792880, ..., 6177236, 8614554,  699501]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## TF-IDF PREDICTION \n",
    "k = 1000\n",
    "documents, tf_idf, vocabulary, idf = tfidf_process_corpus()\n",
    "tfidf_query_vectors = tfidf_vectorize_queries(queries_test, vocabulary, idf)\n",
    "prediction = tfidf_predict_documents(tf_idf, tfidf_query_vectors, k)\n",
    "map_ = predictions_to_ids_ranking(corpus, queries_test, prediction)\n",
    "\n",
    "## DEEP EMBEDDING PREDICTION\n",
    "VECTORIZED_CORPUS = deep_embedder_process_corpus()\n",
    "\n",
    "top_large_k = np.zeros(shape=(map_.shape[0], k))\n",
    "for i in range(map_.shape[0]):\n",
    "    new_line = np.array(map_.iloc[i]['corpus-id'])\n",
    "    for j in range(len(new_line)):\n",
    "        top_large_k[i][j] = new_line[j]\n",
    "\n",
    "top_large_k = top_large_k.astype(int)\n",
    "deep_vectors = deep_vectorize_queries(queries_test)\n",
    "\n",
    "top_large_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                0         1         2         3         4         5    \\\ncorpus-id                                                               \n0          0.036782  0.072424  0.047705  0.034890  0.061811  0.002282   \n8         -0.090315  0.042195 -0.105028  0.105037 -0.022243 -0.026515   \n12         0.079767  0.045493 -0.078602 -0.085799  0.014205  0.094719   \n16         0.055086  0.049693 -0.038150 -0.028982  0.008027  0.053894   \n23         0.028170 -0.006082 -0.052376  0.109535  0.105868  0.052443   \n\n                6         7         8         9    ...       374       375  \\\ncorpus-id                                          ...                       \n0          0.052584  0.013747 -0.006059  0.020383  ...  0.039878  0.038444   \n8          0.027935  0.009226 -0.070801 -0.009509  ... -0.018309  0.102742   \n12        -0.025265 -0.012084 -0.046951  0.026032  ...  0.025857  0.044715   \n16        -0.014112  0.015803 -0.008704  0.026339  ...  0.088978 -0.042638   \n23         0.036321  0.008764  0.019626  0.079031  ... -0.086813 -0.086053   \n\n                376       377       378       379       380       381  \\\ncorpus-id                                                               \n0         -0.033567  0.031575 -0.144267  0.059140  0.148167  0.010506   \n8         -0.020822 -0.029041 -0.027009  0.012926  0.027183 -0.000482   \n12         0.110158  0.046377  0.029626  0.000650  0.017033  0.035821   \n16         0.070218  0.026321 -0.017349  0.025541  0.093563  0.097440   \n23         0.057206  0.038039 -0.045612  0.014078 -0.042592  0.086353   \n\n                382       383  \ncorpus-id                      \n0         -0.032048  0.005427  \n8         -0.089371  0.015834  \n12         0.072192 -0.070197  \n16         0.106132 -0.097305  \n23         0.185973 -0.015787  \n\n[5 rows x 384 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>374</th>\n      <th>375</th>\n      <th>376</th>\n      <th>377</th>\n      <th>378</th>\n      <th>379</th>\n      <th>380</th>\n      <th>381</th>\n      <th>382</th>\n      <th>383</th>\n    </tr>\n    <tr>\n      <th>corpus-id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.036782</td>\n      <td>0.072424</td>\n      <td>0.047705</td>\n      <td>0.034890</td>\n      <td>0.061811</td>\n      <td>0.002282</td>\n      <td>0.052584</td>\n      <td>0.013747</td>\n      <td>-0.006059</td>\n      <td>0.020383</td>\n      <td>...</td>\n      <td>0.039878</td>\n      <td>0.038444</td>\n      <td>-0.033567</td>\n      <td>0.031575</td>\n      <td>-0.144267</td>\n      <td>0.059140</td>\n      <td>0.148167</td>\n      <td>0.010506</td>\n      <td>-0.032048</td>\n      <td>0.005427</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-0.090315</td>\n      <td>0.042195</td>\n      <td>-0.105028</td>\n      <td>0.105037</td>\n      <td>-0.022243</td>\n      <td>-0.026515</td>\n      <td>0.027935</td>\n      <td>0.009226</td>\n      <td>-0.070801</td>\n      <td>-0.009509</td>\n      <td>...</td>\n      <td>-0.018309</td>\n      <td>0.102742</td>\n      <td>-0.020822</td>\n      <td>-0.029041</td>\n      <td>-0.027009</td>\n      <td>0.012926</td>\n      <td>0.027183</td>\n      <td>-0.000482</td>\n      <td>-0.089371</td>\n      <td>0.015834</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.079767</td>\n      <td>0.045493</td>\n      <td>-0.078602</td>\n      <td>-0.085799</td>\n      <td>0.014205</td>\n      <td>0.094719</td>\n      <td>-0.025265</td>\n      <td>-0.012084</td>\n      <td>-0.046951</td>\n      <td>0.026032</td>\n      <td>...</td>\n      <td>0.025857</td>\n      <td>0.044715</td>\n      <td>0.110158</td>\n      <td>0.046377</td>\n      <td>0.029626</td>\n      <td>0.000650</td>\n      <td>0.017033</td>\n      <td>0.035821</td>\n      <td>0.072192</td>\n      <td>-0.070197</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.055086</td>\n      <td>0.049693</td>\n      <td>-0.038150</td>\n      <td>-0.028982</td>\n      <td>0.008027</td>\n      <td>0.053894</td>\n      <td>-0.014112</td>\n      <td>0.015803</td>\n      <td>-0.008704</td>\n      <td>0.026339</td>\n      <td>...</td>\n      <td>0.088978</td>\n      <td>-0.042638</td>\n      <td>0.070218</td>\n      <td>0.026321</td>\n      <td>-0.017349</td>\n      <td>0.025541</td>\n      <td>0.093563</td>\n      <td>0.097440</td>\n      <td>0.106132</td>\n      <td>-0.097305</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.028170</td>\n      <td>-0.006082</td>\n      <td>-0.052376</td>\n      <td>0.109535</td>\n      <td>0.105868</td>\n      <td>0.052443</td>\n      <td>0.036321</td>\n      <td>0.008764</td>\n      <td>0.019626</td>\n      <td>0.079031</td>\n      <td>...</td>\n      <td>-0.086813</td>\n      <td>-0.086053</td>\n      <td>0.057206</td>\n      <td>0.038039</td>\n      <td>-0.045612</td>\n      <td>0.014078</td>\n      <td>-0.042592</td>\n      <td>0.086353</td>\n      <td>0.185973</td>\n      <td>-0.015787</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 384 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VECTORIZED_CORPUS = pd.DataFrame(VECTORIZED_CORPUS, index=corpus['corpus-id'])\n",
    "VECTORIZED_CORPUS.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T21:57:59.018080400Z",
     "start_time": "2023-10-20T21:57:59.014471800Z"
    }
   },
   "id": "e19f2fca83c05eff"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[56], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m top10 \u001B[38;5;241m=\u001B[39m deep_predict_documents(top_large_k, deep_vectors, VECTORIZED_CORPUS)\n\u001B[0;32m      2\u001B[0m top10\n",
      "Cell \u001B[1;32mIn[55], line 13\u001B[0m, in \u001B[0;36mdeep_predict_documents\u001B[1;34m(top_large_k, vectorized_queries, vectorized_corpus)\u001B[0m\n\u001B[0;32m     10\u001B[0m sentence_feature \u001B[38;5;241m=\u001B[39m vectorized_corpus\u001B[38;5;241m.\u001B[39mloc[top_large_k[idx]]  \n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# Dot product (numerator of cosine similarity), similar to linear_kernel\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m similarity \u001B[38;5;241m=\u001B[39m sentence_feature \u001B[38;5;241m@\u001B[39m vector_query\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Get indices of top-k highest similarities\u001B[39;00m\n\u001B[0;32m     16\u001B[0m top_10[idx] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margsort(similarity)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m10\u001B[39m:]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:1630\u001B[0m, in \u001B[0;36mDataFrame.__matmul__\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m   1626\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__matmul__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other: AnyArrayLike \u001B[38;5;241m|\u001B[39m DataFrame) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   1627\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1628\u001B[0m \u001B[38;5;124;03m    Matrix multiplication using binary `@` operator in Python>=3.5.\u001B[39;00m\n\u001B[0;32m   1629\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1630\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdot(other)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:1610\u001B[0m, in \u001B[0;36mDataFrame.dot\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m   1606\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor_sliced(\n\u001B[0;32m   1607\u001B[0m         np\u001B[38;5;241m.\u001B[39mdot(lvals, rvals), index\u001B[38;5;241m=\u001B[39mleft\u001B[38;5;241m.\u001B[39mindex, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1608\u001B[0m     )\n\u001B[0;32m   1609\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(rvals, (np\u001B[38;5;241m.\u001B[39mndarray, Index)):\n\u001B[1;32m-> 1610\u001B[0m     result \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(lvals, rvals)\n\u001B[0;32m   1611\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m   1612\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(result, index\u001B[38;5;241m=\u001B[39mleft\u001B[38;5;241m.\u001B[39mindex, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mdot\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "top10 = deep_predict_documents(top_large_k, deep_vectors, VECTORIZED_CORPUS)\n",
    "top10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T22:18:41.857034900Z",
     "start_time": "2023-10-20T22:18:40.086964900Z"
    }
   },
   "id": "45af34e5-7b67-4970-9a2b-1d1461467535"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "        0    1    2    3    4    5    6    7    8   9\n0       9    6   99   17   16  124    4    2    1   0\n1     120   18   11  310  515   42   10  400  123   2\n2      17   85   40    4   28   16  298    1   19   3\n3     454  205  634  917  347  489  239  561  524  19\n4      57    1   10   48   77  460   60   15  425  83\n...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ..\n7432  723  986   28   38   21   10    0    7    2   1\n7433   10  435  278  764  235  155  146   43  105   0\n7434  512   91   70    3   15  438   23    1   41  35\n7435   14    6    7   58   11   30   15   68    9   0\n7436   22   31   28    9    0    5    6    1   15  25\n\n[7437 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9</td>\n      <td>6</td>\n      <td>99</td>\n      <td>17</td>\n      <td>16</td>\n      <td>124</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>120</td>\n      <td>18</td>\n      <td>11</td>\n      <td>310</td>\n      <td>515</td>\n      <td>42</td>\n      <td>10</td>\n      <td>400</td>\n      <td>123</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17</td>\n      <td>85</td>\n      <td>40</td>\n      <td>4</td>\n      <td>28</td>\n      <td>16</td>\n      <td>298</td>\n      <td>1</td>\n      <td>19</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>454</td>\n      <td>205</td>\n      <td>634</td>\n      <td>917</td>\n      <td>347</td>\n      <td>489</td>\n      <td>239</td>\n      <td>561</td>\n      <td>524</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>1</td>\n      <td>10</td>\n      <td>48</td>\n      <td>77</td>\n      <td>460</td>\n      <td>60</td>\n      <td>15</td>\n      <td>425</td>\n      <td>83</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7432</th>\n      <td>723</td>\n      <td>986</td>\n      <td>28</td>\n      <td>38</td>\n      <td>21</td>\n      <td>10</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7433</th>\n      <td>10</td>\n      <td>435</td>\n      <td>278</td>\n      <td>764</td>\n      <td>235</td>\n      <td>155</td>\n      <td>146</td>\n      <td>43</td>\n      <td>105</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7434</th>\n      <td>512</td>\n      <td>91</td>\n      <td>70</td>\n      <td>3</td>\n      <td>15</td>\n      <td>438</td>\n      <td>23</td>\n      <td>1</td>\n      <td>41</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>7435</th>\n      <td>14</td>\n      <td>6</td>\n      <td>7</td>\n      <td>58</td>\n      <td>11</td>\n      <td>30</td>\n      <td>15</td>\n      <td>68</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7436</th>\n      <td>22</td>\n      <td>31</td>\n      <td>28</td>\n      <td>9</td>\n      <td>0</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1</td>\n      <td>15</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n<p>7437 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(top10)\n",
    "result = result.apply(lambda x: corpus.index.values[x])\n",
    "result\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T22:05:17.477766700Z",
     "start_time": "2023-10-20T22:05:17.458304900Z"
    }
   },
   "id": "74c333db56b493d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
